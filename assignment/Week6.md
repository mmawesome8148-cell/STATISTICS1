# 통계학 6주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_6th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

6주차는 `2부-데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다


## Statistics_6th_TIL

### 2부. 데이터 분석 준비하기

### 11. 데이터 전처리와 파생변수 생성

<!-- 11. 데이터 전처리와 파생변수 생성에서 11.1 결측값 처리부터 11.4 데이터 표준화와 정규화 스케일링 파트까지 진행해주시면 됩니다. -->

## Study ScheduleStudy Schedule

| 주차  | 공부 범위     | 완료 여부 |
| ----- | ------------- | --------- |
| 1주차 | 1부 p.2~46    | ✅         |
| 2주차 | 1부 p.47~81   | ✅         |
| 3주차 | 2부 p.82~120  | ✅         |
| 4주차 | 2부 p.121~167 | ✅         |
| 5주차 | 2부 p.168~202 | ✅         |
| 6주차 | 2부 p.203~250 | ✅         |
| 7주차 | 2부 p.251~299 | 🍽️         |

> 과제가 많이 남지 않았습니다. 조금만 더 화이팅해주세요!

<!-- 여기까진 그대로 둬 주세요-->



---

# 1️⃣ 개념 정리 

## 11.데이터 전처리와 파생변수 생성

```
✅ 학습 목표 :
* 결측값과 이상치를 식별하고 적절한 방법으로 처리할 수 있다.
* 데이터 변환과 가공 기법을 학습하고 활용할 수 있다.
* 모델 성능 향상을 위한 파생 변수를 생성하고 활용할 수 있다.
```

### 11.1. 결측값 처리

- 결측치 처리 방법을 결정하기 전에 데이터 탐색을 통해 결측값의 비율, 분포를 파악해야 함. 
- 간혹 빈 문자열이 결측값으로 인식되지 않을 수도 있으므로 
확인을 해야 함. 
- 결측값은 분석 환경에 따라 `NA`, `NaN`으로 표시됨.
- 결측치 종류: 결측치 발생 특성에 따라 구분됨.
    - 완전 무작위 결측: 결측값이 무작위로 발생한 경우
        - 제거해도 편향이 거의 발생하지 X
    - 비무작위 결측: 컬럼의 특성 때문에 발생하게 된 결측치
        - 예) 소득변수에서의 결측치: 소득정도를 밝히기 싫어서 결측치 발생.
- 결측치 처리 방법
    - `표본 제거 방법`: 결측치가 너무 많은 변수를 제거하거나 결측치가 있는 행을 제거하는 방법
        - 편향 발생 위험 높음.
        - 완전 무작위 결측에만 적합함.
    - `평균 대치법`: 결측값을 제외한 값들의 평균을 구한 다음, 결측치에 그 평균값을 채워넣는 방법 (최빈값, 중앙값, 최댓값, 최솟값으로 대치하기도 함.)
        - 통계량의 표준오차가 왜곡돼서 p-value가 부정확하게 됨.
        - 완전 무작위 결측에만 적합함. 
    - `회귀대치법`: 결측치가 있는 변수와 다른 변수 사이의 관계성을 고려해 결측값
        - 추정하고자하는 결측값을 가진 변수를 종속변수로 설정, 나머지 변수를 독립변수로 설정한 후 회귀식을 통해 결측치에 추정값을 채워넣는 것. 
        - `확률적 회귀대치법`: 인위적으로 회귀식에 확률 오차랑을 추가해서 변동성을 조정하는 방법. 결측된 변수의 분산을 과소 추정하는 문제를 해결할 수 있음. 
        - `다중대치법`: 단순 대치를 여러 번 수행해서 n개의 가상적 데이터를 생성한 후, 이 데이터들의 평균으로 결측값을 대치하는 방법. 단순 대치법들의 표본오차 과소 추정 문제를 해결할 수 있음.
            - 대치 단계: 가능한 대치 값의 분포에서 추출된 서로 다른 값으로 결측치를 처리한 n개의 데이터셋 생성.
                - 1)몬테카를로 방법 
                - 2)다중대치
            - 분석 단계: 생성된 데이터셋을 분석해 모수의 추정치와 표준오차 계산
            - 결합 단계: 각 데이터셋의 추정치와 표준오차를 결합해 최종 결측 대치값을 산출.
- 전체 칼럼의 속성과 결측값들이 얼마나 있는지 확인해야.
- info()함수는 결측값이 아닌 수를 나타내므로 정확한 결측값이 얼마나 되는지 확인하기 어려움. 
- 결측값으로 인식되지 않지만 실제값이 빈 문자열인 값이 있는지 확인해야.
- 결측값의 관측치를 제거할 때는 `dropna()` 함수
- 모든 칼럼의 값이 결측값인 행을 제외할 때는 `how='all'` 옵션을 사용
- 한 칼럼이라도 결측값인 행을 제외할 때는 `how='any'`옵션을 사용
- 특정 칼럼의 결측값을 기준으로 관측치를 제거할 때는 `subset옵션`을 사용. 
- 결측값 대치는 `fillna()`옵션을 활용
- 전 시점이나 뒤 시점의 값과 동일한 값으로 대체하는 보간법은 `method옵션`이나 `pad`, `bfill`로 설정해 적용 -> 앞 시점의 값을 가져올 때는 첫 행이 결측값인 경우, 앞 시점의 데이터가 없기 때문에 채울 수 없음. 똑같이 뒤 시점을 가져올 때는 마지막 행이 결측값이면 대치가 안된다. 
- 시점 인젝스를 사용하여면 시간형 칼럼-> 시계열 객체로 변환 후 인덱스로 설정해야.
- `interpolate()` 함수를 사용해 시점을 고려한 대치값을 채워넣어야.
- 다중 대치는 sklearn의 impute패키지를 활용. 다중 대치 적용시 넘파이 배열로 변환되기 떄문에 다시 판다스 데이터 프레임으로 변환해야. 



### 11.2. 이상치 처리

- `이상치`: 전체 데이터의 범위에서 크게 벗어난, 극잔적인 값
    - 모집단의 평균, 총합 추정 방해
    - 분산을 과도하게 증가시켜 분석과 모델링의 정확도를 감소시킴. 
    - 데이터 양이 많을수록 이상치가 통계값에 미치는 영향력이 줄어들기 때문에 이상치 제거 필요성이 낮아짐. 
- 이상치 처리 방법
    - 트리밍: 이상치 제거
        - 추정치의 분산은 감소하지만 실제값을 과장시키는 편향을 발생시킴.
    - 관측값 변경: 하한, 상한 값을 결정한 후, 하한 값보다 작으면 하한 값으로 대체하고 상한 값보다 크면 상한 값으로 대체하는 방법
    - 가중치 조정: 이상치의 영향력을 감소시키기 위해 가중치를 조정함. 
- 이상치 정의 방법
    - 박스플롯 상에서 분류된 극단치
    - 임의로 허용범위 설정, 이를 벗어나는 자료를 이상치로 정의
- 효과적 이상치 탐색 방법: 데이터 변수들의 의미와 비즈니스 도메인을 먼저 이해한 후에 이상치가 생긴 원인을 생각해야. 
- 분석 도메인에 따라 이상치가 중요한 분석 요인일 수 있음. 특히 불량품의 원인을 찾아야 하는 경우나, 사기 거래를 탐지할 떄 이상치는 유용한 값임.

### 11.3. 변수 구간화

- `변수 구간화`: 이산형 변수를 범주형 변수로 비즈니스적 상황에 맞도록 변환시켜 데이터의 해석이나 예측, 분류 모델을 의도에 맞게 변형할 수 있음. 
    - 이산 값 평활화
        -변수의 값을 일정한 폭이나 빈도로 구간을 나눈 후,
        - 각 구간 안에 속한 데이터의 평균, 중앙값, 경계값으로 변환함.
    - 클러스터링, 의사결정나무

- 변수 구간화 평가 지표: 종속변수 대비 독립변수가 예측력이 얼마나 강한지 나타내는 지표들 (WOE, IV)
    - IV 수치가 높을 수록 종속변수의 트루/펄스를 잘 구분할 수 있는 정보량이 많다는 뜻. 

- `cut()`함수: 를 통해 구간화
- `qcut()` 함수: 변수 자동 구간화
- WOE를 활용해 종속변수에 대한 독립변수가 최적의 예측력을 가질 수 있도록 구간화해야. WOE를 통해 구간화 기준의 IV를 확인해야.


### 11.4. 데이터 표준화와 정규화 스케일링

- 필요한 경우: 독립변수들 끼리의 단위가 다르거나 편차가 심할 때 스케일을 일정하게 바꿔줘야 함. 
- `표준화`: 각 관측치의 값이 전체 평균을 기준으로 어느정도 떨어져있는지 나타낼 때 사용. zero-mean으로부터 얼마나 떨어져있는지를 나타내기 때문에 Z-score라 표현함. 
- `정규화`: 데이터의 범위를 0부터 1까지의 범위로 변환해서 데이터 분포를 조정하는 방법. 즉, 0에 가까울수록 작은 값이고 1에 가까울수록 큰 값인 것.   
    - 표준화는 평균에서 얼마나 떨어져있는지 정도를 나타내기 떄문에 가장 큰 값이 1이 될수도 있고 3.5가 될 수 있는 반면, 정규화의 가장 큰 값은 1, 가장 작은 값은 0으로 표현됨. 
    - 표준화, 정규화 모두 이상치에 민감하다는 약점이 있음.
    - k-Nearest Neighbor, 서포트 벡터 머신처럼 거리를 활용한 클러스터링에서 필수적.
    - 범주화 알고리즘 인공신경망 모델에서도 학습 효율과 분류 성능을 높이기 위해 표준화와 정규화가 필요함. 
- `RobustScaler`: 데이터의 중앙값을 0으로 잡고 Q1과 Q3와의 IQR 차이를 1이 되도록하는 스케일링 기법. 
- 데이터 스케일링 방법
    - 기존 칼럼들의 평균과 분산 확인
    - `StandarScaler()`함수를 사용해 데이터셋을 표준화
    - 표준화된 값은 넘파이 darray형태로 저장되기 때문에 다시 판다스 프레임으로 변환해야. 
    - `MinMaxScaler()`함수를 사용해 데이터를 정규화
    - 스케일링 후 칼럼별 평균, 분산 확인
    - `RobustScaler()`: 평균 대신 중앙값을 사용해서 극단값의 영향을 거의 X받음. 



<br>
<br>

---

# 2️⃣ 확인 과제

> **교재에 있는 실습 파트를 직접 따라 해보세요. 실습을 완료한 뒤, 결과화면(캡처 또는 코드 결과)을 첨부하여 인증해 주세요.**
>
> **단순 이론 암기보다, 직접 손으로 따라해보면서 실습해 보는 것이 가장 확실한 학습 방법입니다.**
>
> > **인증 예시 : 통계 프로그램 결과, 시각화 이미지 캡처 등**

### 11.1.1. 결측치 처리 
![](../images/w6-1.png)
![](../images/w6-2.png)
![](../images/w6-3.png)
![](../images/w6-4.png)
![](../images/w6-5.png)
![](../images/w6-6.png)
![](../images/w6-7.png)
![](../images/w6-8.png)
![](../images/w6-9.png)

### 11.2.1. 이상치 처리
![](../images/w6-10.png)
![](../images/w6-11.png)
![](../images/w6-12.png)
![](../images/w6-13.png)
![](../images/w6-14.png)
![](../images/w6-15.png)

### 11.3.1. 변수 구간화 
![](../images/w6-16.png)
![](../images/w6-17.png)
![](../images/w6-18.png)
![](../images/w6-19.png)
![](../images/w6-20.png)
![](../images/w6-21.png)
![](../images/w6-22.png)
![](../images/w6-23.png)
![](../images/w6-24.png)그냥 영원히 돌아가..제미나이도 해결하지 못함...
![](../images/w6-25.png)

### 11.4.1. 데이터 표준화와 정규화
![](../images/w6-26.png)
![](../images/w6-27.png)
![](../images/w6-28.png)
![](../images/w6-29.png)
![](../images/w6-30.png)
![](../images/w6-31.png)
![](../images/w6-32.png)
![](../images/w6-33.png)
![](../images/w6-34.png)
![](../images/w6-35.png)
![](../images/w6-36.png)
~~~
인증 이미지가 없으면 과제 수행으로 인정되지 않습니다.
~~~



### 🎉 수고하셨습니다.

